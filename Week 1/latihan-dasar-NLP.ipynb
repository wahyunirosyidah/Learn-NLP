{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teori Dasar\n",
    "Dalam NLP, model seperti neural network tidak bisa langsung memproses teks. Oleh karena itu, teks harus diubah menjadi angka atau vektor. Salah satu cara adalah dengan membangun vocabulary (kumpulan kata unik dalam teks) dan memberikan indeks (nomor urut) pada setiap kata.\n",
    "\n",
    "TextVectorization adalah layer di TensorFlow yang membantu membuat vocabulary dari teks dan mengonversi teks menjadi indeks berdasarkan vocabulary tersebut. Layer ini memungkinkan teks mentah diolah menjadi data yang siap diproses oleh model.\n",
    "\n",
    "### Analogi\n",
    "Bayangkan Anda memiliki sebuah kamus (vocabulary) yang hanya berisi kata-kata tertentu. Setiap kata diberi nomor halaman (indeks). Misalnya, \"love\" ada di halaman 3, \"dog\" ada di halaman 2, dan sebagainya. Jadi, jika Anda ingin membaca kalimat \"I love my dog,\" Anda hanya perlu mencari nomor halaman untuk setiap kata di kamus itu. Demikian juga dalam pemrosesan teks, kita membuat \"kamus\" dari kata-kata yang ada dan menggunakan nomor sebagai penggantinya.\n",
    "\n",
    "Tokenize=menandai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets's Code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample inputs\n",
    "sentences=[\n",
    "    'i love your cat', #pliss, jangan sampai lupa koma kalau mau outputnya aneh\n",
    "    'You, Him, and Her love my horse!',\n",
    "    'I, love my dog'\n",
    "]\n",
    "\n",
    "#layer untuk mengonversi teks menjadi angka\n",
    "vectorize_layer=tf.keras.layers.TextVectorization()\n",
    "\n",
    "#menyimpan inputan dalam bentuk index\n",
    "vectorize_layer.adapt(sentences)\n",
    "\n",
    "#membuat vocabulary dengan ignore special tokens\n",
    "vocabulary=vectorize_layer.get_vocabulary(include_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 love\n",
      "1 my\n",
      "2 i\n",
      "3 your\n",
      "4 you\n",
      "5 horse\n",
      "6 him\n",
      "7 her\n",
      "8 dog\n",
      "9 cat\n",
      "10 and\n"
     ]
    }
   ],
   "source": [
    "#Print the token index\n",
    "for index, word in enumerate(vocabulary):\n",
    "    print(index, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walaupun ada huruf i kecil dan besar tetap akan di standarisasi makanya hasilnya muncul i (huruf kecil) saja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Menggunakan token khusus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "1 [UNK]\n",
      "2 love\n",
      "3 my\n",
      "4 i\n",
      "5 your\n",
      "6 you\n",
      "7 horse\n",
      "8 him\n",
      "9 her\n",
      "10 dog\n",
      "11 cat\n",
      "12 and\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabulary list dengan mengambil special token\n",
    "vocabulary = vectorize_layer.get_vocabulary()\n",
    "\n",
    "# Print the token index\n",
    "for index, word in enumerate(vocabulary):\n",
    "  print(index, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penjelasan Peran Token Khusus\n",
    "Token khusus seperti [UNK] dan [PAD] digunakan untuk mengatasi kondisi tertentu:\n",
    "\n",
    "- [UNK] (Unknown) digunakan untuk kata-kata yang tidak ada di vocabulary (tidak dikenali).\n",
    "- [PAD] digunakan untuk penyesuaian panjang kalimat agar bisa diolah dalam batch dengan panjang yang sama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      "1 [UNK]\n",
      "2 love\n",
      "3 my\n",
      "4 i\n",
      "5 your\n",
      "6 you\n",
      "7 horse\n",
      "8 him\n",
      "9 her\n",
      "10 dog\n",
      "11 cat\n",
      "12 and\n",
      "\n",
      "Kalimat 'I love your fish' ditransformasikan menjadi indeks: [4 2 5 1]\n",
      "\n",
      "Kalimat 'They love my chicken' ditransformasikan menjadi indeks: [1 2 3 1]\n",
      "\n",
      "Kalimat 'I love your dog' ditransformasikan menjadi indeks: [ 4  2  5 10]\n"
     ]
    }
   ],
   "source": [
    "#Test new sentence\n",
    "new_sentences=[\n",
    "    'I love your fish',\n",
    "    'They love my chicken',\n",
    "    'I love your dog'\n",
    "]\n",
    "\n",
    "vectorize_sentence=vectorize_layer(new_sentences)\n",
    "\n",
    "for index, word in enumerate(vocabulary):\n",
    "  print(index, word)\n",
    "\n",
    "for i, vec in enumerate(vectorize_sentence):\n",
    "    print(f\"\\nKalimat '{new_sentences[i]}' ditransformasikan menjadi indeks:\", vec.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dalam konteks pemrosesan teks dan machine learning, padding merujuk pada menambahkan nilai khusus (biasanya nol) di akhir atau awal dari sebuah urutan teks (misalnya kalimat) agar semua urutan memiliki panjang yang sama. Padding otomatis dilakukan oleh layer tertentu (seperti TextVectorization di TensorFlow) atau saat kita mempersiapkan data input, sehingga setiap kalimat atau urutan memiliki jumlah kata atau token yang konsisten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: \n",
      "1: [UNK]\n",
      "2: my\n",
      "3: love\n",
      "4: i\n",
      "5: dog\n",
      "6: cat\n",
      "Kalimat 'I love my dog' ditransformasikan menjadi indeks: [4 3 2 5 0]\n",
      "Kalimat 'I love my fish' ditransformasikan menjadi indeks: [4 3 2 1 0]\n",
      "Kalimat 'You love my cat' ditransformasikan menjadi indeks: [1 3 2 6 0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Daftar kalimat awal untuk membangun vocabulary\n",
    "sentences = [\n",
    "    'I love my dog',\n",
    "    'I love my cat'\n",
    "]\n",
    "\n",
    "# Inisialisasi layer TextVectorization dengan output sequence length tertentu\n",
    "# untuk menambahkan padding secara otomatis\n",
    "vectorize_layer = tf.keras.layers.TextVectorization(output_sequence_length=5)\n",
    "\n",
    "# Membuat vocabulary dari kalimat-kalimat awal\n",
    "vectorize_layer.adapt(sentences)\n",
    "\n",
    "# Melihat vocabulary yang dihasilkan\n",
    "vocabulary = vectorize_layer.get_vocabulary()\n",
    "for index, word in enumerate(vocabulary):\n",
    "    print(f\"{index}: {word}\")\n",
    "\n",
    "# Vocabulary yang dihasilkan akan seperti ini:\n",
    "# 0: [PAD]\n",
    "# 1: [UNK]\n",
    "# 2: i\n",
    "# 3: love\n",
    "# 4: my\n",
    "# 5: dog\n",
    "# 6: cat\n",
    "\n",
    "# Tes kalimat baru dengan kata yang tidak ada dalam vocabulary\n",
    "test_sentences = [\n",
    "    'I love my dog',    # Semua kata ada di vocabulary\n",
    "    'I love my fish',   # Kata \"fish\" tidak ada di vocabulary, jadi akan jadi [UNK]\n",
    "    'You love my cat'   # Kata \"You\" tidak ada di vocabulary, jadi akan jadi [UNK]\n",
    "]\n",
    "\n",
    "# Transformasikan kalimat ke dalam bentuk angka\n",
    "vectorized_sentences = vectorize_layer(test_sentences)\n",
    "\n",
    "# Print hasilnya\n",
    "for i, vec in enumerate(vectorized_sentences):\n",
    "    print(f\"Kalimat '{test_sentences[i]}' ditransformasikan menjadi indeks:\", vec.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
